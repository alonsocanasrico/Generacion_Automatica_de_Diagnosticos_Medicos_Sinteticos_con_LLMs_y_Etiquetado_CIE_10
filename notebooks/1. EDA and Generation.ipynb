{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c663dd65",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57daf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfm.settings import settings\n",
    "import matplotlib as plt\n",
    "from tfm.llm.llm_vllm import VLLMLLM\n",
    "from tfm.llm.llm_openai import OpenAILLM\n",
    "from tfm.utils.utils import (\n",
    "    generar_grupos_para_llamadas,\n",
    "    asignacion_proporcional,\n",
    "    procesar_grupo,\n",
    "    clean_text,\n",
    "    read_cie10_file\n",
    ")\n",
    "from tfm.prompt_engineering.data_generation_prompts import (\n",
    "    system_prompt_openai,\n",
    "    user_prompt_openai,\n",
    "    system_prompt_llama,\n",
    "    user_prompt_llama,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35e926",
   "metadata": {},
   "source": [
    "## Parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08642f4f",
   "metadata": {},
   "source": [
    "Con meta-llama/Llama-3.2-3B-Instruct si se elige un CANTIDAD_A_GENERAR_POR_LLAMADA = 15, suele no generar la '}' del final.\n",
    "\n",
    "Si se le deja la temperatura a 0, para un mismo input, generará siempre los mismos diagnósticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0be0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = 'openai'\n",
    "# MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "MODEL = 'vllm'\n",
    "# MODEL_NAME = \"meta-llama/Llama-3.1-8B\"\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# MODEL_NAME = \"merged_models/finetuned-llama-diagnosticos\" # Modelo finetuneado\n",
    "\n",
    "\n",
    "UMBRAL_MINIMO = 100 # Cantidad mínima de ejemplos por etiqueta que debe haber (se generarán hasta UMBRAL_MINIMO por cada etiqueta)\n",
    "CANTIDAD_A_GENERAR_POR_LLAMADA = 5 # cuantos más se generen, menos llamadas habrá que hacer al LLM y por lo tanto, al estar haber más generaciones por llamada y mrnos llamadas, el resultado final será en principio más diverso (porque dentro de una misma llamada no debería hacer dos veces el mismo diagnóstico sintético). además Será más barato porque se harán menos llamadas al LLM, y se repetirán menos los ejemplos de input. Un número demasiado alto podría hacer que no quepa en la ventana de contexto del LLM, por lo que hay que tener cuidado con esto. Aunque la ventana suele ser bastante grande. También existe el riesgo de que \"alucine\" más y termine generando diagnósticos que no corresponden a la etiqueta, ya que tratará de seguir inventando diagnósticos distintos.\n",
    "MAX_EJEMPLOS_INPUT = 5 # cantidad máxima de diganósticos de ejemplo que se le mandarán al LLM en cada llamada.Si se pone un número muy bajo, puede que el modelo no tenga suficiente contexto para generar diagnósticos coherentes. Si se pone un número muy alto, puede que las llamadas que se hagan al modelo sean poco variadas (por lo que se repetirán muchos diagnósticos) y además puede que no quepa en la ventana de contexto del modelo. Por lo tanto, hay que encontrar un equilibrio.\n",
    "TEMPERATURE = 0.5 # Temperatura del modelo. A mayor temperatura, más aleatorio será el resultado, y por lo tanto los ejemplos generados serán más diversos. A menor temperatura, más repetitivo y menos diverso será el resultado, pero habrá menos \"alucinaciones\" y por lo tanto los diagnósticos generados serán más coherentes.\n",
    "FREQUENCY_PENALTY = 0.0 # Penalización por frecuencia de palabras. A mayor penalización, menos repetitivo será el resultado, y por lo tanto los ejemplos generados serán más diversos. A menor penalización, más repetitivo y menos diverso será el resultado, pero habrá menos \"alucinaciones\" y por lo tanto los diagnósticos generados serán más coherentes. Valor entre -2.0 y 2.0.\n",
    "PRESENCE_PENALTY = 0.0 # Penalización por presencia de palabras. A mayor penalización, menos repetitivo será el resultado, y por lo tanto los ejemplos generados serán más diversos. A menor penalización, más repetitivo y menos diverso será el resultado, pero habrá menos \"alucinaciones\" y por lo tanto los diagnósticos generados serán más coherentes. Valor entre -2.0 y 2.0.\n",
    "\n",
    "MAX_RETRIES = 3 # Cantidad máxima de reintentos en caso de error al llamar al LLM. Si se supera este número, se descartará la llamada y se continuará con la siguiente. Esto es útil para evitar que se generen menos datos de los que se deberían generar por errores en la llamada al LLM.\n",
    "MAX_WORKERS = 20  # Número máximo de ejecuciones paralelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL == 'openai':\n",
    "    system_prompt = system_prompt_openai\n",
    "    user_prompt = user_prompt_openai\n",
    "    llm = OpenAILLM(model_name=MODEL_NAME)\n",
    "elif MODEL == 'vllm':\n",
    "    system_prompt = system_prompt_llama\n",
    "    user_prompt = user_prompt_llama\n",
    "    llm = VLLMLLM(model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c2625b",
   "metadata": {},
   "source": [
    "## Leer Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/diagnoses_df/ground_truth_df.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af819bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_diagnosticos = read_cie10_file(\"../data/diagnoses_df/diagnosticos_tipos.csv\")\n",
    "etiquetas_diagnosticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Codigos_diagnosticos_list'] = data['Codigos_diagnosticos'].apply(ast.literal_eval)\n",
    "data['Codigos_diagnosticos_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8038f",
   "metadata": {},
   "source": [
    "## Conteo de etiquetas a nivel individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79861ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [label for sublist in data['Codigos_diagnosticos_list'] for label in sublist]\n",
    "label_counts = Counter(all_labels)\n",
    "label_counts_df = pd.DataFrame(label_counts.items(), columns=['Etiqueta', 'Frecuencia'])\n",
    "label_counts_df.sort_values(by='Frecuencia', ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe559c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts_df.plot(x='Etiqueta', y='Frecuencia', kind='bar', figsize=(18, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d137feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_pobres_df = label_counts_df[label_counts_df['Frecuencia'] < UMBRAL_MINIMO]\n",
    "\n",
    "ejemplos_faltantes = {\n",
    "    row['Etiqueta']: UMBRAL_MINIMO - row['Frecuencia']\n",
    "    for _, row in etiquetas_pobres_df.iterrows()\n",
    "}\n",
    "ejemplos_faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46dd18d",
   "metadata": {},
   "source": [
    "### Comprobar qué códigos pueden aparecer \"solos\" y cuáles solo aparecen acompañados de otros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codes = etiquetas_diagnosticos\n",
    "apariciones = {codigo: {'solo': False, 'acompanado': False} for codigo in all_codes}\n",
    "\n",
    "for lista in data['Codigos_diagnosticos_list']:\n",
    "    es_solo = (len(lista) == 1)\n",
    "    for codigo in lista:\n",
    "        if es_solo:\n",
    "            apariciones[codigo]['solo'] = True\n",
    "        else:\n",
    "            apariciones[codigo]['acompanado'] = True\n",
    "\n",
    "# ódigos que pueden aparecer solos (al menos una vez en lista de 1)\n",
    "codigos_pueden_solo = [c for c, f in apariciones.items() if f['solo']]\n",
    "\n",
    "# Códigos que solo aparecen acompañados (nunca en lista de 1)\n",
    "codigos_solo_acompanado = [c for c, f in apariciones.items() if f['acompanado'] and not f['solo']]\n",
    "\n",
    "print(\"Códigos que pueden aparecer solos:\", codigos_pueden_solo)\n",
    "print(\"Códigos que solo aparecen acompañados:\", codigos_solo_acompanado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplos_faltantes_individuales = {\n",
    "    codigo: ejemplos_faltantes[codigo]\n",
    "    for codigo in codigos_pueden_solo\n",
    "    if codigo in ejemplos_faltantes\n",
    "}\n",
    "ejemplos_faltantes_acompanados = {\n",
    "    codigo: ejemplos_faltantes[codigo]\n",
    "    for codigo in codigos_solo_acompanado\n",
    "    if codigo in ejemplos_faltantes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplos_faltantes_individuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplos_faltantes_acompanados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd2057",
   "metadata": {},
   "source": [
    "## Conteo de grupos de etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f14f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por conjunto (orden no importa, así que usamos set y lo convertimos a tuple ordenado)\n",
    "data['Diagnosticos_normalizados'] = data['Codigos_diagnosticos_list'].apply(lambda x: tuple(sorted(x)))\n",
    "grupo_conjuntos = data.groupby('Diagnosticos_normalizados').size().reset_index(name='Frecuencia')\n",
    "\n",
    "print(\"\\nFrecuencia por conjunto de etiquetas:\")\n",
    "grupo_conjuntos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96985b88",
   "metadata": {},
   "source": [
    "### De los que solo aparecen acompañados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456868cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = grupo_conjuntos[grupo_conjuntos['Diagnosticos_normalizados'].apply(lambda tupla: any(codigo in tupla for codigo in codigos_solo_acompanado))]\n",
    "df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b8137",
   "metadata": {},
   "source": [
    "## Generación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d24ebdf",
   "metadata": {},
   "source": [
    "Para cada etiqueta presente en ejemplos_faltantes hay que generar tantos diagnósticos como se indica. Hay 2 casos en los que hay que generar casi todos a partir de únicamente 1 o 2 ejemplos deisponibles, lo que peude ser complejo (pues es posible que lo que se genere tenga poca diversidad, al partir todos de los mismos ejemplos de base).\n",
    "\n",
    "La idea es, para cada etiqueta, generar ejemplos a partir de los disponibles. Haciendo varias llamadas al LLM, cada una con algunos de los ejemplos disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96167e15",
   "metadata": {},
   "source": [
    "### Para aquellas etiquetas que solamente aparecen acompañadas por otras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplos_faltantes_acompanados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d042967",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosticos_generados_completo_list = []\n",
    "# Para cada etiqueta, hay que usar proporcionalmente los ejemplos disponibles para generar los ejemplos sintéticos.\n",
    "for etiqueta, faltantes in ejemplos_faltantes_acompanados.items():\n",
    "    print(f\"\\n\\nEtiqueta: {etiqueta} - Faltantes: {faltantes}\")\n",
    "    df_acom = data[\n",
    "            data['Codigos_diagnosticos_list']\n",
    "                .apply(lambda lst: etiqueta in lst and len(lst) > 1)\n",
    "        ].copy()\n",
    "    unique_combinations = list(df_acom['Diagnosticos_normalizados'].unique())\n",
    "    grupos_ejemplos = []\n",
    "    for combo in unique_combinations:\n",
    "        grupo = df_acom[df_acom['Diagnosticos_normalizados'] == combo]\n",
    "        ejemplos = grupo['Descripcion_diagnosticos'].tolist()\n",
    "        \n",
    "        etiquetas = grupo['Codigos_diagnosticos'].iloc[0]  \n",
    "        \n",
    "        grupos_ejemplos.append({\n",
    "            \"etiquetas\": etiquetas,\n",
    "            \"ejemplos\": ejemplos\n",
    "        })\n",
    "\n",
    "    tamaños = [len(g['ejemplos']) for g in grupos_ejemplos]\n",
    "    asign = asignacion_proporcional(tamaños, total_faltantes=faltantes)\n",
    "\n",
    "    for ejemplos, falt in zip(grupos_ejemplos, asign):\n",
    "        ejemplos_con_etiqueta = ejemplos['ejemplos']\n",
    "        etiquetas = ejemplos['etiquetas']\n",
    "\n",
    "        if len(ejemplos_con_etiqueta) == 0: # Este caso es cñuando solo hay ejemplos para la etiqueta acompañada de otras etiquetas, y no hay ejemplos únicos para esa etiqueta.\n",
    "            print(f\"\\n\\t\\tGrupo de Etiquetas: {etiquetas} - No hay ejemplos disponibles.\")\n",
    "            \n",
    "        else:\n",
    "            nombres_etiquetas = [etiquetas_diagnosticos[etiqueta] for etiqueta in json.loads(etiquetas.replace(\"'\", '\"'))]\n",
    "            print(f\"\\n\\tGrupo de Etiquetas: {etiquetas} ({nombres_etiquetas}) - Disponibles: {len(ejemplos_con_etiqueta)} | Faltantes: {falt}\")\n",
    "            \n",
    "            grupos = generar_grupos_para_llamadas(ejemplos_con_etiqueta, falt, max_ejemplos_input=MAX_EJEMPLOS_INPUT, generar_por_llamada=CANTIDAD_A_GENERAR_POR_LLAMADA)\n",
    "            print(f\"\\tCantidad de grupos generada: {len(grupos)}\")\n",
    "            diagnosticos_generados_total = []\n",
    "\n",
    "            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "                futures = [\n",
    "                    executor.submit(procesar_grupo, grupo, etiquetas, nombres_etiquetas, CANTIDAD_A_GENERAR_POR_LLAMADA, system_prompt, user_prompt, llm, MAX_RETRIES, TEMPERATURE, FREQUENCY_PENALTY, PRESENCE_PENALTY)\n",
    "                    for grupo in grupos\n",
    "                ]\n",
    "\n",
    "                for future in as_completed(futures):\n",
    "                    try:\n",
    "                        resultado = future.result()\n",
    "                        diagnosticos_generados_total.extend(resultado)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error procesando grupo en paralelo: {e}\")\n",
    "                \n",
    "            print(f\"\\t - Diagnósticos generados final: {len(diagnosticos_generados_total)}\")\n",
    "            for diag in diagnosticos_generados_total:\n",
    "                data_to_append = {\n",
    "                    \"Descripcion_diagnosticos\": diag,\n",
    "                    \"Codigos_diagnosticos\": etiquetas,\n",
    "                    \"Diagnosticos_estandar\": nombres_etiquetas\n",
    "                }\n",
    "                diagnosticos_generados_completo_list.append(data_to_append)\n",
    "        print()\n",
    "generated_groups_df = pd.DataFrame(diagnosticos_generados_completo_list)\n",
    "generated_groups_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8497e0e",
   "metadata": {},
   "source": [
    "### Para aquellas etiquetas que aparecen individualmente (aunque puedan aparecer tambien acompañadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4739b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplos_faltantes_individuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db708cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosticos_generados_completo_list = []\n",
    "# Para cada etiqueta, hay que usar proporcionalmente los ejemplos disponibles para generar los ejemplos sintéticos.\n",
    "for etiqueta, faltantes in ejemplos_faltantes_individuales.items():\n",
    "    ejemplos_con_etiqueta = list(data[data['Codigos_diagnosticos_list'].apply(lambda x: 'F68.0' in x and len(x)==1)]['Descripcion_diagnosticos'].unique())\n",
    "    if len(ejemplos_con_etiqueta) == 0: # Este caso es cuando solo hay ejemplos para la etiqueta acompañada de otras etiquetas, y no hay ejemplos únicos para esa etiqueta.\n",
    "        print(f\"\\nEtiqueta: {etiqueta} - No hay ejemplos disponibles.\")\n",
    "        \n",
    "    else:\n",
    "        nombre_etiqueta = etiquetas_diagnosticos[etiqueta]\n",
    "        print(f\"\\nEtiqueta: {etiqueta} ({nombre_etiqueta}) - Disponibles: {len(ejemplos_con_etiqueta)} | Faltantes: {faltantes}\")\n",
    "        \n",
    "        # Filtrar los ejemplos que contienen la etiqueta actual\n",
    "        grupos = generar_grupos_para_llamadas(ejemplos_con_etiqueta, faltantes, max_ejemplos_input=MAX_EJEMPLOS_INPUT, generar_por_llamada=CANTIDAD_A_GENERAR_POR_LLAMADA)\n",
    "        print(f\"Cantidad de grupos generada: {len(grupos)}\")\n",
    "        diagnosticos_generados_total = []\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "            futures = [\n",
    "                executor.submit(procesar_grupo, grupo, etiquetas, nombres_etiquetas, CANTIDAD_A_GENERAR_POR_LLAMADA, system_prompt, user_prompt, llm, MAX_RETRIES, TEMPERATURE, FREQUENCY_PENALTY, PRESENCE_PENALTY)\n",
    "                for grupo in grupos\n",
    "            ]\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    resultado = future.result()\n",
    "                    diagnosticos_generados_total.extend(resultado)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error procesando grupo en paralelo: {e}\")\n",
    "            \n",
    "        print(f\"\\t - Diagnósticos generados final: {len(diagnosticos_generados_total)}\")\n",
    "        for diag in diagnosticos_generados_total:\n",
    "            data_to_append = {\n",
    "                \"Descripcion_diagnosticos\": diag,\n",
    "                \"Codigos_diagnosticos\": f\"['{etiqueta}']\",\n",
    "                \"Diagnosticos_estandar\": [nombre_etiqueta]\n",
    "            }\n",
    "            diagnosticos_generados_completo_list.append(data_to_append)\n",
    "    print()\n",
    "generated_singles_df = pd.DataFrame(diagnosticos_generados_completo_list)\n",
    "generated_singles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e5869",
   "metadata": {},
   "source": [
    "## Dataset_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb46aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generados = pd.concat([generated_groups_df, generated_singles_df], ignore_index=True)\n",
    "df_generados.insert(1, 'Descripcion_diagnosticos_limpio', df_generados['Descripcion_diagnosticos'].apply(clean_text).to_list())\n",
    "df_generados['generated'] = True\n",
    "df_generados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a51f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['generated'] = False\n",
    "df_final = pd.concat([data.drop([col for col in data.columns if col not in df_generados.columns], axis=1), df_generados], ignore_index=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Codigos_diagnosticos_list'] = df_final['Codigos_diagnosticos'].apply(ast.literal_eval)\n",
    "\n",
    "all_labels = [label for sublist in df_final['Codigos_diagnosticos_list'] for label in sublist]\n",
    "label_counts = Counter(all_labels)\n",
    "label_counts_df = pd.DataFrame(label_counts.items(), columns=['Etiqueta', 'Frecuencia'])\n",
    "label_counts_df.sort_values(by='Frecuencia', ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c013cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts_df.plot(x='Etiqueta', y='Frecuencia', kind='bar', figsize=(18, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_pobres_df = label_counts_df[label_counts_df['Frecuencia'] < UMBRAL_MINIMO]\n",
    "\n",
    "ejemplos_faltantes = {\n",
    "    row['Etiqueta']: UMBRAL_MINIMO - row['Frecuencia']\n",
    "    for _, row in etiquetas_pobres_df.iterrows()\n",
    "}\n",
    "ejemplos_faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_filename = (\n",
    "    f\"../data/generated/\"\n",
    "    f\"MODEL_{MODEL}_\"\n",
    "    f\"MODELNAME_{MODEL_NAME.replace('/', '-')}_\" # Sustituir la barra diagonal por un guión para evitar problemas con el nombre del archivo\n",
    "    f\"UMBRALMIN_{UMBRAL_MINIMO}_\"\n",
    "    f\"CANTXCALL_{CANTIDAD_A_GENERAR_POR_LLAMADA}_\"\n",
    "    f\"MAXINP_{MAX_EJEMPLOS_INPUT}_\"\n",
    "    f\"TEMP_{TEMPERATURE}_\"\n",
    "    f\"FREQPEN_{FREQUENCY_PENALTY}_\"\n",
    "    f\"PRESENCEPEN_{PRESENCE_PENALTY}.csv\"\n",
    ")\n",
    "df_final.to_csv(final_df_filename, index=False)\n",
    "final_df_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905018f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    'creation_timestamp': datetime.now().isoformat(),\n",
    "    'Model': MODEL,\n",
    "    'Model_name': MODEL_NAME,\n",
    "    'Umbral_minimo': UMBRAL_MINIMO,\n",
    "    'Cantidad_a_generar_por_llamada': CANTIDAD_A_GENERAR_POR_LLAMADA,\n",
    "    'Max_ejemplos_input': MAX_EJEMPLOS_INPUT,\n",
    "    'Temperature': TEMPERATURE,\n",
    "    'Frequency_penalty': FREQUENCY_PENALTY,\n",
    "    'Presence_penalty': PRESENCE_PENALTY\n",
    "}\n",
    "with open(final_df_filename.replace('.csv', '.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(params_dict, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
